{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import preprocessing\n",
    "from agents.matchmanager import buildMatchManager\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.feature_selection import RFE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors=[]\n",
    "df=pd.DataFrame()\n",
    "winners=[]\n",
    "if __name__ == '__main__':\n",
    "    for p in ['PlayerDummy','AlphaBetaAgent']:\n",
    "        for p1 in ['PlayerDummy','AlphaBetaAgent']:\n",
    "        \n",
    "            mm = buildMatchManager('', 'scenarioTest1v1', p, p1, seed=42)\n",
    "\n",
    "            while not mm.end:\n",
    "                mm.nextStep()\n",
    "                vectors.append(mm.state.vector())\n",
    "            old=df.shape[0]\n",
    "            df=pd.DataFrame(vectors)\n",
    "            new=df.shape[0]\n",
    "            for i in range(new-old):\n",
    "                winners.append(mm.winner)\n",
    "              \n",
    "    df['win']=winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=df.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in c.array:\n",
    "    value=df[i].unique()\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(value)\n",
    "    df[i]=le.transform(df[i])\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(df):\n",
    "   \n",
    "    X = df.drop('win',1)\n",
    "    y = df['win'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    proba = clf.predict_proba(X_test)\n",
    "    proba = np.around(proba, decimals=2)\n",
    "\n",
    "\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # feature importanti per determinarlo\n",
    "    feature_imp = pd.Series(clf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "    print('Feature importance', feature_imp)\n",
    "\n",
    "    # Creating a bar plot\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    # Add labels to your graph\n",
    "    plt.xlabel('Feature Importance Score')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title(\"Visualizing Important Features\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    #return X_test, y_test, y_pred, proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_variance(df):\n",
    "    X = df\n",
    "    sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "    return sel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recur_cross(df):\n",
    "    X = df.drop('win',1)\n",
    "    y = df['win'].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "\n",
    "    # Create the RFE object and compute a cross-validated score.\n",
    "    svc = SVC(kernel=\"linear\")\n",
    "    # The \"accuracy\" scoring is proportional to the number of correct\n",
    "    # classifications\n",
    "    rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(2),\n",
    "                  scoring='accuracy')\n",
    "    rfecv.fit(X_train, y_train)\n",
    "    print(\"anche qui\")\n",
    "\n",
    "    print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "    # Plot number of features VS. cross-validation scores\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "    plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recur(df):\n",
    "    X = df.drop('win',1)\n",
    "    y = df['win'].values\n",
    "\n",
    "    # Create the RFE object and rank each pixel\n",
    "    svc = SVC(kernel=\"linear\", C=1)\n",
    "    rfe = RFE(estimator=svc, n_features_to_select=1, step=1)\n",
    "    rfe.fit(X, y)\n",
    "    ranking = rfe.ranking_.reshape(df.shape)\n",
    "\n",
    "    # Plot pixel ranking\n",
    "    plt.matshow(ranking, cmap=plt.cm.Blues)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Ranking of pixels with RFE\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectfrommodel(df):\n",
    "    X = df.drop('win',1)\n",
    "    y = df['win'].values\n",
    "\n",
    "    feature_names = X.columns\n",
    "    print(feature_names)\n",
    "    clf = LassoCV().fit(X, y)\n",
    "    importance = np.abs(clf.coef_)\n",
    "    print(importance)\n",
    "    idx_third = importance.argsort()[-3]\n",
    "    threshold = importance[idx_third] + 0.01\n",
    "\n",
    "    idx_features = (-importance).argsort()[:2]\n",
    "    name_features = np.array(feature_names)[idx_features]\n",
    "    print('Selected features: {}'.format(name_features))\n",
    "\n",
    "    sfm = SelectFromModel(clf, threshold=threshold)\n",
    "    sfm.fit(X, y)\n",
    "    X_transform = sfm.transform(X)\n",
    "\n",
    "    n_features = sfm.transform(X).shape[1]\n",
    "    plt.title(\n",
    "        \"Features from diabets using SelectFromModel with \"\n",
    "        \"threshold %0.3f.\" % sfm.threshold)\n",
    "    feature1 = X_transform[:, 0]\n",
    "    feature2 = X_transform[:, 1]\n",
    "    plt.plot(feature1, feature2, 'r.')\n",
    "    plt.xlabel(\"First feature: {}\".format(name_features[0]))\n",
    "    plt.ylabel(\"Second feature: {}\".format(name_features[1]))\n",
    "    plt.ylim([np.min(feature2), np.max(feature2)])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove low variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "var=low_variance(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recur(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "feature_names = diabetes.feature_names\n",
    "print(feature_names)\n",
    "clf = LassoCV().fit(X, y)\n",
    "importance = np.abs(clf.coef_)\n",
    "print(importance)\n",
    "idx_third = importance.argsort()[-3]\n",
    "threshold = importance[idx_third] + 0.01\n",
    "\n",
    "idx_features = (-importance).argsort()[:2]\n",
    "name_features = np.array(feature_names)[idx_features]\n",
    "print('Selected features: {}'.format(name_features))\n",
    "\n",
    "sfm = SelectFromModel(clf, threshold=threshold)\n",
    "sfm.fit(X, y)\n",
    "X_transform = sfm.transform(X)\n",
    "\n",
    "n_features = sfm.transform(X).shape[1]\n",
    "plt.title(\n",
    "    \"Features from diabets using SelectFromModel with \"\n",
    "    \"threshold %0.3f.\" % sfm.threshold)\n",
    "feature1 = X_transform[:, 0]\n",
    "feature2 = X_transform[:, 1]\n",
    "plt.plot(feature1, feature2, 'r.')\n",
    "plt.xlabel(\"First feature: {}\".format(name_features[0]))\n",
    "plt.ylabel(\"Second feature: {}\".format(name_features[1]))\n",
    "plt.ylim([np.min(feature2), np.max(feature2)])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
