{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicol\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Nicol\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Nicol\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Nicol\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Nicol\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Nicol\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import preprocessing\n",
    "from agents.matchmanager import buildMatchManager\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.feature_selection import RFE\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicol\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Nicol\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Nicol\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Nicol\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from agents.matchmanager import MatchManager\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from agents import GreedyAgent, AlphaBetaAgent, RandomAgent\n",
    "from scenarios import scenarioJunction, scenarioJunctionExo, scenarioTest1v1, scenarioTest2v2\n",
    "from core.const import RED, BLUE\n",
    "from agents.ml.simple import SimpleMLAgent\n",
    "\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(mm.st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board, state = scenarioJunction()\n",
    "playerRed = SimpleMLAgent(RED, {'scenario': board.name, 'model': 'RandomForestClassifier'})\n",
    "playerBlue = SimpleMLAgent(BLUE, {'scenario': board.name, 'model': 'RandomForestClassifier'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = MatchManager(' ', playerRed, playerBlue, board, state, seed=43)\n",
    "while not mm.end:\n",
    "    mm.nextStep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "players=['RandomAgent']\n",
    "#scenarios=['scenarioTest1v1', 'scenarioTest2v2', 'scenarioTest3v1','scenarioJunction', 'scenarioJunctionExo', 'scenarioRoadblock', 'scenarioBridgeHead']\n",
    "scenarios=['scenarioJunction']\n",
    "if __name__ == '__main__':\n",
    "        for s in scenarios:\n",
    "            vectors=[]\n",
    "            winners=[]\n",
    "            df=pd.DataFrame()\n",
    "            for i in range(1):\n",
    "\n",
    "                for p in players:\n",
    "                    for p1 in players:\n",
    "                        mm = buildMatchManager('', s, p, p1, seed=random.randint(0,10000))\n",
    "                        #print('Player 1',p)\n",
    "                        #print('Player 2',p1)\n",
    "                        #print('SCenario',s)\n",
    "\n",
    "                        while not mm.end:\n",
    "                            mm.nextStep()\n",
    "                            vectors.append(mm.state.vector())\n",
    "                        old=df.shape[0]\n",
    "                        df=pd.DataFrame(vectors)\n",
    "                        new=df.shape[0]\n",
    "                        for i in range(new-old):\n",
    "                            winners.append(mm.winner)\n",
    "\n",
    "            df.columns=mm.state.vectorInfo()\n",
    "            df['winner']=winners\n",
    "\n",
    "            #print('ehi'+s)\n",
    "            df.to_csv(r'../docs/csv/csv'+s+'.csv')\n",
    "            #print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-aad1a5b04755>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates_history\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mm' is not defined"
     ]
    }
   ],
   "source": [
    "mm.states_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.state.lastAction.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.state.lastAction.team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['positionZ_red_2_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import GM\n",
    "from core.actions import Action\n",
    "from core.game.board import GameBoard\n",
    "from core.game.state import GameState\n",
    "from agents import Agent, GreedyAgent\n",
    "import numpy as np\n",
    "from core.const import RED, BLUE\n",
    "import pandas as pd\n",
    "import os.path as op\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['color_red_2_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=joblib.load('C:\\\\Users\\\\Nicol\\\\Documents\\\\Master\\\\SecondoProgetto\\\\newtechnowar-webui\\\\code\\\\models\\\\Junction_RandomForestClassifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=[]\n",
    "for figure in state.getFiguresCanBeActivated(RED):\n",
    "    actions = [GM.actionPassFigure(figure)] + \\\n",
    "              GM.buildAttacks(board, state, figure) + \\\n",
    "              GM.buildMovements(board, state, figure)\n",
    "    for action in actions:\n",
    "        newState, outcome = GM.activate(board, state, action)\n",
    "\n",
    "        X = np.array(newState.vector()).reshape(1, -1)\n",
    "        cols = newState.vectorInfo()\n",
    "        df = pd.DataFrame(data=X, columns=cols)\n",
    "        score = model.predict_proba(df)\n",
    "\n",
    "        scores.append((score, action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestActionRandom(scores):\n",
    "    sorted_multi_list = sorted(scores, key=lambda x: x[0][0][0])\n",
    "    if (BLUE):\n",
    "        bestAction=random.choice(sorted_multi_list[-10:])[1]\n",
    "    else:\n",
    "        bestAction=random.choice(sorted_multi_list[:10])[1]\n",
    "    return bestAction\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestScore, bestAction = 0.0, None\n",
    "#print(sorted(scores, reverse=True))\n",
    "\n",
    "for probs, action in scores:\n",
    "    print(probs)\n",
    "    if (BLUE):\n",
    "        score = probs[0, 0]\n",
    "        print(\"ehi\",score)\n",
    "        print(action)\n",
    "    else:\n",
    "        score = probs[0, 1]\n",
    "        print(score)\n",
    "    if score >= bestScore:\n",
    "        bestScore, bestAction = score, action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for probs, action in scores:\n",
    "    print(entropy(probs[0], base=len(scores)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
