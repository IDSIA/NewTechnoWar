{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "import joblib\n",
    "from sklearn import metrics\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../../data.scenarioJunctionExo.pkl.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_save(df):\n",
    "    X = df.drop('winner', axis=1)\n",
    "    y = df['winner']    \n",
    "    #categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    c=df.select_dtypes(include=['object']).drop(['winner'], axis=1).columns\n",
    "    preprocessor = ColumnTransformer(transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), c)])\n",
    "    rf = Pipeline(steps=[('preprocessor', preprocessor),('classifier', RandomForestClassifier())])\n",
    "    rf.fit(X, y)\n",
    "    return(rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipelineClassifier(df):   \n",
    "    X = df.drop('winner', axis=1)\n",
    "    y = df['winner']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    c=df.select_dtypes(include=['object']).drop([['winner', 'meta_scenario', 'meta_p_red', 'meta_p_blue', 'meta_seed']], axis=1,errors=\"ignore\").columns\n",
    "    preprocessor = ColumnTransformer(transformers=[('cat', categorical_transformer, c)])\n",
    "    classifiers = [\n",
    "        KNeighborsClassifier(3),\n",
    "        SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "        NuSVC(probability=True),\n",
    "        DecisionTreeClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "        AdaBoostClassifier(),\n",
    "        GradientBoostingClassifier()\n",
    "        ]\n",
    "    for classifier in classifiers:\n",
    "        pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('classifier', classifier)])\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_pred=pipe.predict(X_test)\n",
    "        print(classifier)\n",
    "        print(\"model score: %.3f\" % pipe.score(X_test, y_test))\n",
    "        print(\"model accuracy:\",metrics.accuracy_score(y_test,y_pred))\n",
    "        #print(\"model f1 score:\",metrics.f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipelineClassifierCross(df):   \n",
    "    X = df.drop('winner', axis=1)\n",
    "    y = df['winner']\n",
    "    cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    c=df.select_dtypes(include=['object']).drop(['winner'], axis=1).columns\n",
    "    preprocessor = ColumnTransformer(transformers=[('cat', categorical_transformer, c)])\n",
    "    classifiers = [\n",
    "        KNeighborsClassifier(3),\n",
    "        #SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "        NuSVC(probability=True),\n",
    "        DecisionTreeClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "        AdaBoostClassifier(),\n",
    "        GradientBoostingClassifier()\n",
    "        ]\n",
    "    for classifier in classifiers:\n",
    "        pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('classifier', classifier)])\n",
    "        scores = cross_val_score(pipe, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "        print(classifier.__class__.__name__)\n",
    "        print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineClassifierCross(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=joblib.load('model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
