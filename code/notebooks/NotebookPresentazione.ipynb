{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import preprocessing\n",
    "from agents.matchmanager import buildMatchManager\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.feature_selection import RFE\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2873, 80)\n",
      "2873\n",
      "0       blue\n",
      "1       blue\n",
      "2       blue\n",
      "3       blue\n",
      "4       blue\n",
      "        ... \n",
      "2868     red\n",
      "2869     red\n",
      "2870     red\n",
      "2871     red\n",
      "2872     red\n",
      "Name: win, Length: 2873, dtype: object\n",
      "(8125, 240)\n",
      "8125\n",
      "0       blue\n",
      "1       blue\n",
      "2       blue\n",
      "3       blue\n",
      "4       blue\n",
      "        ... \n",
      "8120    blue\n",
      "8121    blue\n",
      "8122    blue\n",
      "8123    blue\n",
      "8124    blue\n",
      "Name: win, Length: 8125, dtype: object\n",
      "(8446, 240)\n",
      "8446\n",
      "0        red\n",
      "1        red\n",
      "2        red\n",
      "3        red\n",
      "4        red\n",
      "        ... \n",
      "8441    blue\n",
      "8442    blue\n",
      "8443    blue\n",
      "8444    blue\n",
      "8445    blue\n",
      "Name: win, Length: 8446, dtype: object\n"
     ]
    }
   ],
   "source": [
    "players=['RandomAgent','AlphaBetaAgent','GreedyAgent']\n",
    "#scenarios=['scenarioTest1v1', 'scenarioTest2v2', 'scenarioTest3v1','scenarioJunction', 'scenarioJunctionExo', 'scenarioRoadblock', 'scenarioBridgeHead']\n",
    "scenarios=['scenarioTest1v1','scenarioJunctionExo','scenarioJunction']\n",
    "if __name__ == '__main__':\n",
    "        for s in scenarios:\n",
    "            vectors=[]\n",
    "            winners=[]\n",
    "            df=pd.DataFrame()\n",
    "            for i in range(20):\n",
    "\n",
    "                for p in players:\n",
    "                    for p1 in players:\n",
    "                        mm = buildMatchManager('', s, p, p1, seed=random.randint(0,10000))\n",
    "                        #print('Player 1',p)\n",
    "                        #print('Player 2',p1)\n",
    "                        #print('SCenario',s)\n",
    "\n",
    "                        while not mm.end:\n",
    "                            mm.nextStep()\n",
    "                            vectors.append(mm.state.vector())\n",
    "                        old=df.shape[0]\n",
    "                        df=pd.DataFrame(vectors)\n",
    "                        new=df.shape[0]\n",
    "                        for i in range(new-old):\n",
    "                            winners.append(mm.winner)\n",
    "\n",
    "            df.columns=mm.state.vectorInfo()\n",
    "            print(df.shape)\n",
    "            print(len(winners))\n",
    "            df['win']=winners\n",
    "\n",
    "            #print('ehi'+s)\n",
    "            df.to_csv(r'../docs/csv/csv'+s+'.csv')\n",
    "            #print(df)\n",
    "            print(df['win'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=df.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in c.array:\n",
    "    value=df[i].unique()\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(value)\n",
    "    df[i]=le.transform(df[i])\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(df):\n",
    "   \n",
    "    X = df.drop('win',1)\n",
    "    y = df['win'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    proba = clf.predict_proba(X_test)\n",
    "    proba = np.around(proba, decimals=2)\n",
    "\n",
    "\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # feature importanti per determinarlo\n",
    "    feature_imp = pd.Series(clf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "    print('Feature importance', feature_imp)\n",
    "\n",
    "    # Creating a bar plot\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    # Add labels to your graph\n",
    "    plt.xlabel('Feature Importance Score')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title(\"Visualizing Important Features\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    #return X_test, y_test, y_pred, proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_variance(df):\n",
    "    X = df\n",
    "    sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "    return sel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recur_cross(df):\n",
    "    X = df.drop('win',1)\n",
    "    y = df['win'].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "\n",
    "    # Create the RFE object and compute a cross-validated score.\n",
    "    svc = SVC(kernel=\"linear\")\n",
    "    # The \"accuracy\" scoring is proportional to the number of correct\n",
    "    # classifications\n",
    "    rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(2),\n",
    "                  scoring='accuracy')\n",
    "    rfecv.fit(X_train, y_train)\n",
    "    print(\"anche qui\")\n",
    "\n",
    "    print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "    # Plot number of features VS. cross-validation scores\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "    plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recur(df):\n",
    "    X = df.drop('win',1)\n",
    "    y = df['win'].values\n",
    "\n",
    "    # Create the RFE object and rank each pixel\n",
    "    svc = SVC(kernel=\"linear\", C=1)\n",
    "    rfe = RFE(estimator=svc, n_features_to_select=1, step=1)\n",
    "    rfe.fit(X, y)\n",
    "    ranking = rfe.ranking_.reshape(df.shape)\n",
    "\n",
    "    # Plot pixel ranking\n",
    "    plt.matshow(ranking, cmap=plt.cm.Blues)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Ranking of pixels with RFE\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectfrommodel(df):\n",
    "    X = df.drop('win',1)\n",
    "    y = df['win'].values\n",
    "\n",
    "    feature_names = X.columns\n",
    "    print(feature_names)\n",
    "    clf = LassoCV().fit(X, y)\n",
    "    importance = np.abs(clf.coef_)\n",
    "    print(importance)\n",
    "    idx_third = importance.argsort()[-3]\n",
    "    threshold = importance[idx_third] + 0.01\n",
    "\n",
    "    idx_features = (-importance).argsort()[:2]\n",
    "    name_features = np.array(feature_names)[idx_features]\n",
    "    print('Selected features: {}'.format(name_features))\n",
    "\n",
    "    sfm = SelectFromModel(clf, threshold=threshold)\n",
    "    sfm.fit(X, y)\n",
    "    X_transform = sfm.transform(X)\n",
    "\n",
    "    n_features = sfm.transform(X).shape[1]\n",
    "    plt.title(\n",
    "        \"Features from diabets using SelectFromModel with \"\n",
    "        \"threshold %0.3f.\" % sfm.threshold)\n",
    "    feature1 = X_transform[:, 0]\n",
    "    feature2 = X_transform[:, 1]\n",
    "    plt.plot(feature1, feature2, 'r.')\n",
    "    plt.xlabel(\"First feature: {}\".format(name_features[0]))\n",
    "    plt.ylabel(\"Second feature: {}\".format(name_features[1]))\n",
    "    plt.ylim([np.min(feature2), np.max(feature2)])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var=low_variance(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recur(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recur_cross(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectfrommodel(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
